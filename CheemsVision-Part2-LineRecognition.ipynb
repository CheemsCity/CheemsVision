{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riconoscimento Linee\n",
    "\n",
    "Ora che abbiamo calibrato la camera possiamo dedicarci al primo e fondamentale passo per un algoritmo di guida autonoma: il **riconoscimento delle linee stradali**.\n",
    "\n",
    "La città di CheemsCity è caratterizzata da strade nere con linee bianche a segnalarne i bordi e tutte le analisi che andremo a fare adesso si baseranno su questo assunto;  \n",
    "qual'ora il vostro robot viaggiasse in una città con regole diverse vi basterà cambiare poche cose."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice Omografica\n",
    "\n",
    "La **matrice omografica** è un particolare tipo di matrice che ci permette di passare facilmente da un sistema di riferimento ad un altro, ed è molto utile per descrivere rototraslazioni.   \n",
    "Noi andremo a calcolare la matrice che codifica il passaggio dal sistema di riferimento della foto a quello del mondo reale (da 2D a 3D), in particolare il centro del nuovo sistema di  \n",
    "riferimento si troverà nella proiezione sul terreno del centro della fotocamera."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poter calcolare la matrice vi occorrerà il foglio con la scacchiera che dovreste aver stampato nel punto precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from picamera import PiCamera"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo ora ad importare la configurazione che avevamo effettuato nel foglio precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "file = open(\"part1/FinalCalibration.yml\", \"r\")\n",
    "calibration_data = yaml.load(file, Loader=yaml.UnsafeLoader)\n",
    "matrix = calibration_data['camera_matrix']\n",
    "dist_coef = calibration_data['distortion_coefficient']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo quindi una mappa che permetterà di correggere gli errori della camera in modo veloce.  \n",
    "**NOTA**: *mappa è spesso usato come sinonimo di funzione.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TO-DO: inserire dimensioni dell'immagine o fare programma che calcola.\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(\n",
    "                cam_matrix, dist_coeff, None, cam_matrix, (w, h), 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo ora una funzione che ci permetterà di sfruttare questa mappa per la correzzione delle immagini.\n",
    "\n",
    "**TIPS**: *l'utilizzo del try and else ci permette di gestire eventuali problemi, è molto consigliato il suo utilizzo in casi in cui l'utente potrebbe involontariamente andare a creare problemi.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def undistort_faster(image, mapx, mapy):\n",
    "    try:\n",
    "        return cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posizioniamo la scaccchiera a terra e mettiamo la camera nell'apposito spazio. Una volta fatto andiamo a definire delle variabili che ne indicheranno la distanza dal punto zero dello scacchiera.\n",
    "\n",
    "1. **offsety**: distanza lungo l'asse parallelo al lato più vicino della scacchiera.\n",
    "2. **offsetx**: distanza camera-scacchiera, asse perpendicolare a questa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "camera_calibration_square_size: 0.018\n",
    "offsety = 3 * camera_calibration_square_size\n",
    "offsetx = 0.102 \n",
    "board_offset = np.array([offsetx, -offsety])\n",
    "nx = #nx\n",
    "ny = #ny"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E ora come nel caso precedente della calibrazione della camera, sfrutteremo le foto per il calcolo della matrice omogenea. Il vantaggio è che in questo caso ce ne servirà solo una. Il primo blocco è per chi utilizza una picamera, il secondo per quelle USB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import picamera\n",
    "#programma per picamera raspberry pi\n",
    "\n",
    "camera = Picamera()\n",
    "print(\"avvio camera\")\n",
    "camera.start_preview()\n",
    "print(\"foto tra 4 secondi\")\n",
    "time.sleep(4)\n",
    "photo_name = \"part2/foto/omografia.jpg\"\n",
    "camera.capture(photo_name)\n",
    "camera.stop_preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#programma per camera nativa o USB\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    print(\"avvio camera\")\n",
    "    ret, image = cam.read()\n",
    "\tcv2.imshow('photo',image)\n",
    "\tk = cv2.waitKey(1)\n",
    "    if k == ord(s):\n",
    "        photo_name = \"part2/foto/omografia.jpg\"\n",
    "        cv2.imwrite(photo_name, image)\n",
    "    if k == ord(q):\n",
    "\t\tbreak"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlliamo che la foto scattata sia valida per la calibrazione, in caso contrario rirunna le celle precedenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image = glob.glob('part2/foto/omografia.jpg')\n",
    "\n",
    "for fname in image:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (nx,ny), None)\n",
    "    if ret == True:\n",
    "        total = total + 1\n",
    "print(\"numero di foto buone: {}\".format(total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo e cerchiamo i punti necessari per la calibrazione, saranno gli stessi del foglio precedente.\n",
    "\n",
    "**NOTA:** *andiamo ad effetturare un reverse sui punti perchè gli array numpy hanno l'origine in alto a sinistra, mentro noi la vogliamo in basso a sinistra. Questo però ci porterebbe ad avere il punto nella parte alta e sinistra della scacchiera associato con l'ultima coordinata, ottenendo così un'immagine speculare e per questo dovremo andare a moltiplicare la prima riga della matrice omografica per -1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "src_pts = []\n",
    "for r in range(ny):\n",
    "    for c in range(nx):\n",
    "        src_pts.append(\n",
    "            np.array([r * square_size, c * square_size],\n",
    "                        dtype='float32') + board_offset)\n",
    "\n",
    "src_pts.reverse()\n",
    "\n",
    "imgpoints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, corners = cv.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "if ret == True:\n",
    "    corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "    imgpoints.append(corners2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procediamo a calcolare la matrice grazie alla funzione di opencv e successivamente salviamola in un file yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "H, _mask = cv2.findHomography(\n",
    "        imgpoints.reshape(len(imgpoints), 2),\n",
    "        np.array(src_pts), cv2.RANSAC)\n",
    "\n",
    "#vedere se funziona\n",
    "H[1,:] = H[1,:] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "calibration_data = {\n",
    "    calibration_data = {\n",
    "            \"H_matrix\": H,\n",
    "}\n",
    "with open('part2/Homography.yml', 'w') as outfile:\n",
    "    yaml.dump(calibration_data, outfile, default_flow_style = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riconoscimento linee codice ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che abbiamo la matrice omografica possiamo passare alla parte principale del tutorial; in breve quello che andremo a fare sarà:\n",
    "1) estrarre tutti i pixel di color bianco dall'immagine.\n",
    "2) cercare i punti con gradiente più alto nell'immagine.\n",
    "3) intersecare i due risultati per ottenere un riconosciento ottimale.\n",
    "4) trovare delle rette nell'immagine risultato."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiamo mostrando tutti i passaggi su un'immagine di prova, e poi andremo a definire una pipeline riutilizzabile per processare immagini real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TO-DO: definire importazione immagine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a rettificare l'immagine utilizzando la funzione definita prima (undistort_faster);  \n",
    "Creeremo poi 2 copie in modo da non andare a modificare direttamente l'immagine di partenza con i filtri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image = undistort_faster(image, mapx, mapy)\n",
    "lane_image = np.copy(image[200:, :, :])\n",
    "canny_image = np.copy(image[200:, :, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sulla prima immagine copiata andremo ad applicare tutti gli algoritmi legati al filtraggio per colore, mentre nella seconda quelli legati alla ricerca di rette."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO-DO: parlare della convenzione HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sens = 100\n",
    "lower_white = np.array([0, 0, 255 - sens])  #convenzione HSV\n",
    "upper_white = np.array([255, sens, 255])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procediamo ora ad isolare i pixel di colore bianco, ottenendo così una matrice con le stesse dimensioni dell'immagine e valore True dove presente i pixel bianchi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "frameHSV = cv2.cvtColor(lane_image, cv2.COLOR_BGR2HSV)\n",
    "frameHSV = cv2.inRange(frameHSV, lower_white, upper_white)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per evitare di trovarci con linee spezzate o bucate utilizziamo una trasformazione morfologica basata su un kernel 3x3 chiamata [dilate]('https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#STEP 3: chiudere eventuali buchi con un dilate:\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "frameHSV = cv2.dilate(frameHSV, kernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo ora ad applicare l'algoritmo canny sulla seconda immagine (speigare brevemente canny e mettere link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "edges = cv2.Canny(canny_image, 80, 200, apertureSize=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniamo ora i due risultati -> le 2 immagini saranno infatti caratterizzate da 2 colori (bianco e nero, True o False) e sarà quindi possibile eseguire un'operazione di intersezione tra queste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "edge_color = cv2.bitwise_and(frameHSV, edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerchiamo ora delle rette nell'immagine attraverso l'algoritmo Hough (mettere spiegazione breve e link). Spiegare anche brevemente parametri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(edge_color,\n",
    "                        rho=1,\n",
    "                        theta=np.pi / 180,\n",
    "                        threshold=2,\n",
    "                        minLineLength=3,\n",
    "                        maxLineGap=1,\n",
    "                        lines=np.array([]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-DO: inserire rappresentazione di queste rette nell'immagine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora abbiamo un insieme di punti legati alle rette trovate dall'algoritmo Hough, questi punti saranno definiti nel sistema di riferimento dell'immagine. Per un ottimo controllo di un eventuale veicolo sarà bene trasformarle nel sistema di riferimento del robot tramite la matrice omografica."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l'algoritmo Hough ritornerà un array nX4, composto quindi da n righe di valori x1,y1,x2,y2. Quello che facciamo è dividere i 4 punti in 2 array, il primo contenente solo i punti 1 (x1,y1), il secondo solo quelli 2. Come ultimo passaggio aggiungiamo il primo array ad una lista contenente tutti i punti 1 e il secondi ad una lista contenente tutti i punti 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        p1, p2 = line.reshape(2, 2)\n",
    "        road_points_p1.append(p1)\n",
    "        road_points_p2.append(p2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poter lavorare più facilmente con i punti trasformiamo le liste in array numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "road_vec1 = np.array(road_points_p1, ndmin=2)\n",
    "road_vec2 = np.array(road_points_p2, ndmin=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricordiamo che i punti sono stati calcolati su un'immagine tagliata, per garantire quindi la veridicità della trasformazione dovrò aggiungere l'altezza del pezzo tagliato ai valori dell'altezza dei punti. Questo verrà fatto creando un array (0,h) e sommandolo agli array dei punti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "roi_h = 200\n",
    "roi_vect = np.array((0, roi_h))\n",
    "\n",
    "road_vec1 = (road_vec1 + roi_vect)\n",
    "road_vec2 = (road_vec2 + roi_vect)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definiamo ora una funzione sky_view_points per il calcolo di questi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    def sky_view_points(points, H):\n",
    "        vector = np.append(points, np.array([1]))\n",
    "        ground_point = np.dot(H, vector)\n",
    "        x = ground_point[0]\n",
    "        y = ground_point[1]\n",
    "        z = ground_point[2]\n",
    "\n",
    "        skyPoints = np.array([(y / z), (x / z)])\n",
    "        return skyPoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creiamo due nuove liste contenente i valori dei punti ma post trasformazione omografica. Come prima procediamo poi a trasformarla in un array numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "numPoints = road_vec1.shape[0] if road_vec1.shape[1] == 2 else 0\n",
    "sky_list1 = []\n",
    "sky_list2 = []\n",
    "for i in range(numPoints):\n",
    "    sky_list1.append(sky_view_points(Road_vec1[i, :]))\n",
    "    sky_list2.append(sky_view_points(Road_vec2[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sky_points1 = np.array(sky_list1, ndmin=2)\n",
    "sky_points2 = np.array(sky_list2, ndmin=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
